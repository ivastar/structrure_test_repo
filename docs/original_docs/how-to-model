
HOW TO RUN THE 2ND HALF OF THE PIPELINE
---------------------------------------

Written by Kevin Stevenson,	Jan 2, 2009
Updated instructions - Feb 27, 2009
Updated instructions - Nov 23, 2009
Updated instructions - Aug 09, 2010
Updated instructions - Feb 10, 2011 (mhardin)
Updated instructions - Mar 10, 2011 (kevin)
Updated instructions - Mar 18, 2011 (kevin)
Updated instructions - Sep 10, 2012 (patricio)
Updated instructions - Feb 18, 2013 (patricio)


These instructions use hd149bs11 (HD 149026b) as an example.  Every line of every step is important so if you don't understand, please ask someone who does before moving on.

Make sure you have the following lines in your .bashrc file:
	export PYTHONPATH=.:/home/esp01/code/lib/python
	alias svncomodel='svn co file:///home/esp01/svn/code/python/trunk/pipeline'
Then source the file:
	source ~/.bashrc
It is VERY important that your sys.path no longer includes /home/esp01/ancil/modelparams.

Check out the most current version of the pipeline into the photometry output directory using SVN.  In this case, we're checking out the pipeline into a new directory called '2011-03-10-kevin' but you will want to use your user name and the current date.  If this is your first data set and you have multiple aperture sizes to choose from, pick something between 3.50 and 4.00 pixels to get started.
	cd /home/esp01/events/hd149026b/hd149bs11/run/fgc/ap3750715/
    svncomodel 2011-03-10-kevin

Open the p5checks log file and scroll down to the bottom.  This file will take some time to load.
    gedit hd149bs11_p5.log &
Verify the following:
	The event name is correct.
	The Kurucz filename is correct (located in /home/esp01/ancil/kurucz/)
	The filter filename is correct (located in /home/esp01/ancil/filter/)
    The photometry method is correct (aperture or optimal)
    The HJD/BJD light-time correction is within a couple seconds of Spitzer's estimated correction.
	The number of good frames is > 95% (except for MIPS data)
    The mean x and y positions are reasonable.
    Note the RMS precision.  Round these values up to use as initial estimates for your BLISS map bin sizes.
    The center and photometry aperture sizes are correct.
    The period and ephemeris time are correct and up-to-date
	The plots are consistent with what you might expect
If you don't know if the filenames are correct or what to expect then ask someone who does know.
The phase can be updated by rerunning p5checks while supplying new period and ephemeris values.
If you need to make changes to the event object, resave using poetSave() in run.py.

In your current run directory, open run.py then start iPython.  You can run in BASH mode later once all of the files have been set up correctly.
    cd 2011-03-10-kevin(
	gedit run.py &
	ipython -pylab

From run.py, copy and paste the initial block of code (mostly imports) into your Python session.  Always verify that there are no errors.
    #Sample block of code below, do not use!
    from __future__ import print_function
    import os, sys
    os.environ['OMP_NUM_THREADS']='10'
    import cPickle as pickle
    import matplotlib.pyplot as plt
    import np_unpickle as unpic
    import numpy as np
    import printoutput
    import readeventhdf
    sys.path.append('../')
    from run import *
    ancildir      = 'ancil/'
    modeldir      = 'ancil/modelparams/'
    sys.path.append('./' +ancildir)
    sys.path.append('../'+ancildir)
    isinteractive = True

Load the POET savefile.
    event = poetRestore(filedir='..')

Upon running poetRestore(), the 'ancil' directory is automatically created and populated with your model parameters and initial parameters files from /home/esp01/ancil/modelparams.  If a file doesn't exist, it is generated from a template.

Exit your iPython session and open the model parameters file.
    Exit
	gedit ancil/hd149bs11params.py &

Update the variables for the current event, if necessary:
    planetname = 'HD 149026b'
    #Name of file containing initial parameter values, should be located in the 'ancil' directory.
    modelfile  = ['hd149bs11-initvals.txt']
    #SPECIFY OUTPUT TYPE FOR print STATEMENTS
    #USE sys.stdout FOR STANDARD OUTPUT (TO SCREEN) OR "results.txt" TO WRITE TO A FILE
    printout   = "results-keyword.txt"
    #CHOOSE 'orbits' OR 'days' FOR MODELING AND PLOTING TIME UNIT
    timeunit = 'orbits'
    tuoffset = 0.0
    #Model names and descriptions listed in /home/esp01/doc/models.txt.
    model = [['mandelecl', 'linramp', 'bilinint'],
             ['mandelecl', 'linramp', 'nnint']]
    #Model Constants
    numit      = np.array([1e3, 1e4])       #Number of iterations, [burn-in,final]
    nbins      = 60                         #Number of bins
    chi2flag   = 1                          #1: Adjust sigma s.t. reduced Chi^2 = 1
    numcalc    = 50000                      #Number of temperature calculations
    stepsize   = 10                         #Stepsize for histograms and correlation plots
    rmsbins    = 5000                       #Max number of bins in RMS calc
    allplots   = True                       #Disply all plots (True) or display only some plots (False)
    leastsq    = True                       #Perform least-squares fit before MCMC
    normflux   = True                       #Normalize flux at each position (set False for posflux)
    
    preclip    = [0]                        #Remove first 'preclip' points
    postclip   = [0]                        #Remove last 'postclip' points
    #interclip  = [[lower,upper]]           #Remove points within specified range from model fits,
                                            #Can handle multiple ranges
    #Bin sizes for interpolative ip models
    xstep      = [0.01]                     #Bin size in x
    ystep      = [0.01]                     #Bin size in y
    minnumpts  = [1]                        #Minimum # of points in a bin
    isfixipmap = False                      #Fix intrapixel mapping to best-fit values after burn-in
    sssteps    = [1,2,3,4,6,8,10,30,100,300,1000]
    #ipclip     = [[lower,upper]]           #Remove points within specified range from intrapixel mapping
    #Smoothing parameters
    issmoothing= False                      #Turn smoothing on/off (True/False)
    nx         = [3]                        #Kernel halfwidth in x
    ny         = [3]                        #Kernel halfwidth in y
    sx         = [2.0]                      #Gaussian kernel std dev in x
    sy         = [2.0]                      #Gaussian kernel std dev in y
    #When using quadip4, otherwise set to 0
    xdiv       = 0.0                        #Divide into quadrants here along x axis
    ydiv       = 0.0                        #Divide into quadrants here along y axis
These are suggested initial values so learn what each of these parameters does to determine what you need.  If you are using multiple models (this example has two), keywords with brackets can have one element that applies to all models or one element for each model.  This is very useful for running multiple models with different bin sizes, for example.  Select the number and types of models to use. Instructions and variable definitions are also given in /home/esp01/doc/models.txt.  Save.
	Model types and corresponding save code in ():
        ECLIPSES: 
            mandelecl (m1), mandelecl2 (m2), mandelecl2 (m3)
        TRANSITS: 
            trnlldsp (tsp1), trnlldsp2 (tsp2), mandeltr (t1), mandeltr2 (t2)
        RAMPS: 
            risingexp (re), relramp (rel), reqramp (req), re2ramp (re2)
            fallingexp (fe), felramp (fel)
            logramp (lg), llramp (ll), lqramp (lq), log4qramp (l4q)
            quadramp (qd), linramp (ln)
        SINUSOIDAL:
            sincos (sc), sindecay (sd)
        POSITION:
            posflux (pf), posfluxlinip (pflip)
        VISIT SENSITIVITY:
            vsll (vsll), vsspline (vss)
        INTRA-PIXEL: 
            bilinint (bli), nnint (nni), ballardip (bip)
            quadip (qip), quadip4 (qip4), cubicip (cip), sexticipc (6ipc)

Open the initial parameters file.  This file lists the models and their initial values.
    gedit ancil/hd149bs11-initvals.txt

The parameters are presented in a table headed by the name of each model. Column headers are unique to each model, but rows follow a standard format:
	Row 1: Initial parameters
	Row 2: Lower bounds
	Row 3: Upper bounds
	Row 4: Step size
NOTE 1: To set one parameter equal to another, set its stepsize to the negative value of the location of the parameter you wish it to be equal to. CAUTION: The first location is 1, NOT 0, since you can't have -0.
    eg. To set t12 = t34, set stepsize[3] = -5
NOTE 2: Zero stepsize results in a fixed value.

If you are modeling a secondary eclipse, the first model you will want to setup is 'mandelecl'.  Find the eclipse (or transit) duration and ingress/egress time in the .tep file, convert them to phase units, then insert the values into the first row of 'width', 't12', and 't34'.  Set their step sizes (row 4) to zero.  Select reasonable initial guesses, lower and upper bounds, and step sizes for the remaining parameters.  To see an example initial parameters file with reasonable step sizes for most parameters, see /home/esp01/ancil/modelparams/eg00-initvals.txt.

Continue this process for each ramp and intra-pixel model you intend to test.  See /home/esp01/doc/models.txt for a full description of each model.

In your current run directory, start iPython (assuming you wish to run interactively).  If you want to run your models in BASH mode, read the instructions at the start of run.py and skip the next section.
    ipython -pylab

From run.py, copy and paste the initial block of code (mostly imports) into your Python session.  Always verify that there are no errors.

Load the POET savefile.
    event = poetRestore(filedir='..')
    
Run p6model.
    p6model(event, newdir='SomethingDescriptiveAboutThisRun')
    
This is where the real work begins...

****Feel free to edit/clarify the instructions below****

Below, I try to describe the general steps that I follow when
analyzing a data set for the first time.  With time, you may develop
your own method but until then, I strongly recommend that you stick to
this script.

1. Start with a photometry run that uses a reasonable aperture size, usually
   3.5 - 4.0 pixels.

2. Look at the figures from p5checks and decide what type of ramp models might
   work and whether or not BLISS mapping is needed.
    
3. Find the eclipse/transit using your initial combination of models
   and 1e3 MCMC iterations. Look at the output and adjust upper or
   lower bounds, if necessary. Adjust ramp step sizes until the
   acceptance rate is between 30 and 70%.  Smaller step sizes increase
   the acceptance rate but there is usually only one rate-limiting
   step size.  Adjusting other step sizes will have little to no
   effect on the acceptance rate (See update of 10-09-2012 below).
    
4. Repeat Step 3 for other ramp models.  CH1+2 models typically use linear,
   quadratic or risingexp ramps, CH3 models typically use fallingexp, and CH4
   models typically use risingexp (with preflash) or re2ramp (without
   preflash).  Test lots of ramps and pick a few of the best ramps for now.
   Adjust preclip, postclip or interclip, if necessary.

5. Model the other aperture sizes.  Always look at the output to make sure
   every model has found the eclipse/transit.  Some models simply won't work
   at all aperture sizes while others will only need their upper or lower
   bounds adjusted.
    
6. Record the SDNR for each combination of models at every aperture size in
   the output files, in your log and in Google Wave.  Compare your results to
   find the aperture size with the lowest SDNR.  If using BLISS map go to Step
   7, otherwise go to Step 9.

7. Pick your best ramp model at your best aperture size.  Run bilinint and
   nnint models at various bin sizes.  Find the smallest bin size in x and y
   where bilinint is consistently better than nnint according to SDNR or BIC.
   Larger bin sizes favor bilinint but bin sizes that are too large may affect
   the eclipse/transit depth.  If you cannot find a reasonable bin size then
   BLISS mapping may not be necessary.  Make sure 'minnumpts' = [1] for these
   tests but, once you've settled on your bin size, increase the value to 4 or
   more.  Make sure bilinint is still better than nnint.

8. Rerun Step 6 with your new BLISS map.  Record the results.  The best
   aperture size should not change.

9. Show your results to someone who has done this before.

10. Run all model combinations for 1e6 iterations at your best aperture size.
    All models should produce reasonable acceptance rates.  Look at Figs 6*4
    for correlations between parameters and Figs 6*5 for Gaussian
    distributions.  Discard model combinations that are correlated with
    eclipse/transit depth, if any.  Try fixing t0 and/or t1 parameter values
    in the exponential ramps if they correlate with m.  Pick the model with
    the lowest BIC value as long as the eclipse/transit depth is reasonable.


Once you are happy with your final model, run p7anal, p8tables, and
p9figs to compute brightness temperatures and obtain standard tables
and figures that can be used for publication.

p7anal(event)
p8tables(event)
p9figs(event)


**** Updated instructions - 10-09-2012 (patricio)  *****

p6model has been reimplemented and so, a few changes have been introduced.

The first thing that changed is the order of analyses within p6:
The old scheme:
- chisq-minimization
- burn-in
- chisq-minimization
- sigma rescaling
- full MCMC

Changed to:
- chisq-minimization
- sigma rescaling
- chisq-minimization
- burn-in
- full MCMC

Secondly, we changed from running a single MCMC chain to run many
parallel chains, in this way we perform a more complete exploration of
the phase-space.

Differential Evolution MC is now available (DEMC,
http://www.springerlink.com/content/wp158537l7845w11/?MUD=MP), which
is easier to work with since the user doesn't need to specify and
manually adjust each parameter's proposal stepsize (as with the
Metropolis Random Walk algorithm).

Instead, for DEMC the stepsize values (from the ancilliary initparams
file) will be used to initialize the chains. The code starts from the
best fitting values, and will use the stepsizes to calculate random
values, normal-distributed around the best-fitting value (with
standard deviation=stepsize), thus stepsize determines the dispersion
of the starting point of the chains. Their function as defining fixed
and shared parameters is kept.

A third change is that now p6 is broken into the burn-in and the final
MCMC run, wich can be run separatedly.  The idea is to run the burn-in
results to check that the chain has converged, and only then run the
final MCMC.

p6model should be run like this (from the bash):

# To run the burn-in section (The brackets represent optional
# parameters, don't put them when running the code):

./run.py p6 [newdir=burninMCMC] [mode=burn] [numit=1e3]
./run.py p6 [burninMCMC] [mode=burn] [numit=1e3]  # or equivalently

# if you specified numit in the command call, that will override the
# params file value.
# That creates the folder: 2012-09-07_11:02-burninMCMC/

# If it is necessary, you can continue the burn-in simulation with the
# following command: 

./run.py p6 mode=continue filedir=2012-09-07_11\:02-burninMCMC/ [numit=1e4]

# This will run a new burn-in simulation, starting from the last
# iteration from the previous run. The results will concatenated.

# As you see, the number of iteration can be redefined with in the
# command.  If it's not specified, then it will use the same value
# from the ancilliary params file.

# If you see that one of the chains is stuck with an unphysical set of
# parameters, then re-start the burn-in simulation.

# After the burn in, a plot will show the trace of all the chains for
# each parameter. This helps to check that the chains have
# converged. A second plot of the normalized model for the last
# iteration in each chain helps to check that the chains have not
# found unphysical fitting parameters.

# You can continue the burn-in as meny times as you consider necessary.
# After the burn in, the code will produce two plots that will help to 

# After you are satisfied with the burn-in, you can run the final MCMC
# simulation with the following command:

./run.py p6 mode=final filedir=2012-09-07_11\:02-burninMCMC/ [numit=1e5]

# IMPORTANT: At the end of the final MCMC, the code will join all the
# chains into one long run, so, if you have numit=1e5 and nchains=10,
# the total length of your simulation is 1e6.



*****  Updated instructions  Feb 18, 2013  *****

POET Update:
- Since SVN version 692, POET can run automatically from p1 to p5. You
need to set in the poet control files (pcf), the parameters runp2,
runp3, runp4, and runp5 to True.
Be careful to not use all of our CPUs!, other people need to work as well.
Also be sure to properly set up ALL the pcf files of this section of POET.

p6model upgrades:
- Now you can run the burn-in and final MCMC runs at once. Just set
mode=full when calling p6.

- Also you can choose not to append the date-time to the beginning of
the output modeling dir by setting: nodate=True
Advice: I suggest you still add the date when doing this e.g.:
./run.py p6 2013-02-11-new_modeling nodate=True mode=full


Light-curve automation:
- Finally, you will notice once you checkout POET two new folders:
scripts/ and plots/, and a new file run/lcmodel.py.
- lcmodel.py lets you to run p6model for multiple data sets (apertures),
produces plots of SDNR, Eclipse depth, and BIC vs aperture size
(stores them in the plots/ folder), and saves the data (in the
scripts/ folder).

To run the multiple datasets p6model, you need:

1.- Edit the first lines of lcmodel.py:
"""
centerdir = "all"  # "all" or list e.g.: ["fgc"]
photdir   = "all"  # "all" or list e.g.: ["ap2500715", "ap3000715"]
repodir   = "yyyy-mm-dd-model"   # Name of SVN repository dir
modeldir  = "yyyy-mm-dd_sdnr-compare"  # Name of p6 modeling dir
eventname = "xo003bs21" # Name of your event (do not miss-spell it!)
"""

2.- Go to the scripts/ folder and edit eg00params.py and eg00-initvals.txt.

Put reasonable values in the eg00-initvals.txt file. And set the
models you want to test in the eg00params.py file.
Don't change the names of the files, only their content!

3.- Go to the run/ folder and execute in the prompt:
lcmodel.py

4.- Relax and wait.

5.- Send bug reports when found.

After the code finishes running, it will save the apertures, SDNR,
depth, and BIC information in a .py file in scripts/. You can
copy/paste/edit these files to easily redo the plots at will.

The scripts folder also contains the file results_script.py that you
can use to edit and make the plots without running lcmodel.py if you
already have the data.

Advices to run lcmodel.py:
- Always run it once for a single dataset to make sure your configuration
  of the ancil files are correct and return reasonable fits.
- You don't need to get the depth uncertainties for all the models you
  attempt. So if you care only on SDNR, run with a small number of
  iterations.
- Once you determined the best data set, try running lcmodel.py for
  the best (or the 2 best) models with a larger number of iterations.

